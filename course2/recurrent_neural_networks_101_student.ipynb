{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqrIflpUDm0Y"
      },
      "source": [
        "# Recurrent models 101"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8w6o6rKDopU"
      },
      "source": [
        "Introduction:\n",
        "Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs), and Long Short-Term Memory networks (LSTMs) are powerful tools in the realm of deep learning, particularly for sequential data tasks. In this practical, we'll delve into the basics of these architectures, implement simple models using PyTorch, and verify their functionality by feeding them random data of varying sizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b-aXZ3sDyal"
      },
      "source": [
        "In this practical, you are going to implement small recurrent models (RNNs, GRUs, LSTMs ...) and test them using different input values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5x_QfafDEaQy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bK9ZQ80EIWN"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65yceCRkEJe3"
      },
      "source": [
        "Implement a small RNN model with a single RNN layer\n",
        "\n",
        "You can have a look at pytorch documentation: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
        "\n",
        "In the model, just give the output and the hidden state of the RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MIN3eWPjEdTT"
      },
      "outputs": [],
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        # FIXME\n",
        "\n",
        "    def forward(self, x):\n",
        "        # FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-zXpcR-FjIR"
      },
      "source": [
        "Let's test your model. Test it with different sequence length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bI1owYIFRGp",
        "outputId": "346a04a3-3cd4-40cc-c7bb-ea61f8453fe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([3, 10, 20])\n",
            "Hidden state shape: torch.Size([1, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "# TEST your model, and send random data with torch.randn\n",
        "\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoV8lSDVFFoi"
      },
      "source": [
        "Now implement a bidirectional RNN, you just have one line to change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HdSepL6GFPmi"
      },
      "outputs": [],
      "source": [
        "class BidirectionalRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(BidirectionalRNN, self).__init__()\n",
        "        # FIXME\n",
        "\n",
        "    def forward(self, x):\n",
        "        # FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsCUJbA3Kzu7",
        "outputId": "154ccea3-4e4b-40ef-f200-6f070eac4579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([3, 10, 40])\n",
            "Hidden state shape: torch.Size([2, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "# TEST your model, and send random data with torch.randn\n",
        "\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47LVlxBGFWcS"
      },
      "source": [
        "Let's implement stacked RNNs (use multiple layers of the model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mxRWEyN_FZXz"
      },
      "outputs": [],
      "source": [
        "class BidirectionalRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        # FIXME\n",
        "\n",
        "    def forward(self, x):\n",
        "        # FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzq_4Sd9MJFR",
        "outputId": "4c41e402-7e12-432c-828e-2c778d273450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([3, 15, 20])\n",
            "Hidden state shape: torch.Size([5, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "# TEST your model, and send random data with torch.randn\n",
        "\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPgGrbNwFZkz"
      },
      "source": [
        "Now connect one of the previous models with a single linear layer for binary classification.\n",
        "\n",
        "Use the last output generated by the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3BR0wP-8Ff_g"
      },
      "outputs": [],
      "source": [
        "# Define RNN model\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        # FIXME\n",
        "\n",
        "    def forward(self, x):\n",
        "        # FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8lkq4GPE41k",
        "outputId": "ed0c90e3-db31-4108-ad78-cbfcb0dcf109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "# TEST your model, and send random data with torch.randn\n",
        "\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY095ZoiN5YA"
      },
      "source": [
        "Now implement a simple GRU model, without any Linear layer\n",
        "\n",
        "You can check pytorch documentation: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jp52EZ48N8xf"
      },
      "outputs": [],
      "source": [
        "# Define GRU model\n",
        "class SimpleGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(SimpleGRU, self).__init__()\n",
        "        # FIXME\n",
        "\n",
        "    def forward(self, x):\n",
        "        # FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F0MN0XkODL6",
        "outputId": "f42fc388-2d89-4ed2-82c9-94829295cebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([3, 15, 20])\n",
            "Hidden shape: torch.Size([1, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "# TEST your model, and send random data with torch.randn\n",
        "\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FamzExwUPZOZ"
      },
      "source": [
        "Implement a small LSTM model. Return the output and the hidden state.\n",
        "\n",
        "You can check pytorch documentation.\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rVsqa2t9Phn3"
      },
      "outputs": [],
      "source": [
        "# Define LSTM model\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        # FIXME\n",
        "\n",
        "    def forward(self, x):\n",
        "        # FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zFF8o5_OFAj",
        "outputId": "882b83ee-8666-48eb-e076-abdc1d6297e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([3, 15, 20])\n",
            "Hidden shape: torch.Size([1, 3, 20])\n",
            "Cell shape: torch.Size([1, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "# TEST your model, and send random data with torch.randn\n",
        "\n",
        "# FIXME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
