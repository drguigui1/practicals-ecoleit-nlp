{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent models 101"
      ],
      "metadata": {
        "id": "J_9Vw5CGuYfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the evolving landscape of Natural Language Processing (NLP), Recurrent Neural Networks (RNNs) stand out for their unique ability to process sequential data, making them particularly suited for text analysis tasks. This practical exercise is designed to provide hands-on experience with RNNs, focusing on their application in classifying product reviews as either positive or negative."
      ],
      "metadata": {
        "id": "FqEV3eNzvABm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product reviews, ubiquitous across online platforms, serve as valuable data for extracting consumer sentiments and preferences. However, the unstructured nature of text data poses a challenge for traditional machine learning models. RNNs, with their sequential data processing capability, offer a robust solution to this challenge. By considering the temporal dynamics of language, RNNs can capture contextual nuances critical for accurately interpreting sentiments."
      ],
      "metadata": {
        "id": "_GhY0dSAvFKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This practical will guide you through the end-to-end process of leveraging RNNs for sentiment analysis, encompassing the following steps:\n",
        "\n",
        "- Reading the Dataset: We begin by importing a dataset comprising product reviews, each tagged with additional information such as review summary, verification status of the purchase, timestamp, adjusted log votes, and a binary indicator of the review's sentiment (positive or negative).\n",
        "- Exploratory Data Analysis (EDA): Before delving into modeling, we will conduct a preliminary analysis to understand the dataset's characteristics and distribution.\n",
        "- Dataset Splitting: The dataset will be divided into training and validation sets to evaluate the model's performance.\n",
        "- Text Processing and Transformation: We will preprocess the text data, converting it into a format suitable for RNN processing.\n",
        "- Data Batching and Iterator Creation: This step involves creating batches of data and iterators for efficiently feeding data into the model during training.\n",
        "- Utilizing Pre-trained GloVe Word Embeddings: To enhance the model's understanding of language semantics, we will use GloVe (Global Vectors for Word Representation), a pre-trained word embedding.\n",
        "- Setting Hyperparameters and Building the Network: We will configure the RNN's hyperparameters and architecture.\n",
        "- Training the Model: The network will be trained on the prepared dataset.\n",
        "- Validation: The trained model's performance will be evaluated on the validation dataset.\n",
        "- Improvement Ideas: We will explore strategies for further enhancing the model's accuracy.\n",
        "\n",
        "\n",
        "An important distinction to note is that while RNNs excel in processing textual data, incorporating additional features such as timestamps, log_votes, and verification status requires integrating RNNs with traditional neural network models. This practical will thus not only familiarize you with RNNs but also illustrate how to combine them with other neural network architectures to leverage both sequential and non-sequential data for comprehensive analysis.\n"
      ],
      "metadata": {
        "id": "-TdanDtcvMXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this practical you need to use torchtext"
      ],
      "metadata": {
        "id": "dqOwi5FRwMVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import torchtext, GloVe vocabulary and get_tokenizer function from torchtext"
      ],
      "metadata": {
        "id": "RuoouBzuwWRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchtext\n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "zd5J3z9uwSkY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HaCcPReouUI1"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch, torchtext\n",
        "import pandas as pd\n",
        "from torch import nn, optim\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can download the dataset using this link: https://drive.google.com/file/d/1k1XD0XPRSCC4tGGX1LUN-uzrmlQNJjs2/view?usp=sharing\n",
        "\n",
        "Then you can upload the dataset on your drive or directly in colab.\n",
        "\n",
        "Now, Let's read the dataset:"
      ],
      "metadata": {
        "id": "XynBVyDYwg_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('./AMAZON-REVIEW-DATA-CLASSIFICATION.csv')"
      ],
      "metadata": {
        "id": "gtmp1eC1wKeg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MTD23oFmx7Gs",
        "outputId": "fb33e7d2-0056-45cc-ac79-c37a14eec66e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          reviewText  \\\n",
              "0  PURCHASED FOR YOUNGSTER WHO\\nINHERITED MY \"TOO...   \n",
              "1                              unable to open or use   \n",
              "2   Waste of money!!! It wouldn't load to my system.   \n",
              "3  I attempted to install this OS on two differen...   \n",
              "4  I've spent 14 fruitless hours over the past tw...   \n",
              "\n",
              "                                             summary  verified        time  \\\n",
              "0                                IDEAL FOR BEGINNER!      True  1361836800   \n",
              "1                                          Two Stars      True  1452643200   \n",
              "2                                       Dont buy it!      True  1433289600   \n",
              "3  I attempted to install this OS on two differen...      True  1518912000   \n",
              "4                                   Do NOT Download.      True  1441929600   \n",
              "\n",
              "   log_votes  isPositive  \n",
              "0   0.000000         1.0  \n",
              "1   0.000000         0.0  \n",
              "2   0.000000         0.0  \n",
              "3   0.000000         0.0  \n",
              "4   1.098612         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd620bfc-fff1-4298-a78a-67f12c83e393\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>verified</th>\n",
              "      <th>time</th>\n",
              "      <th>log_votes</th>\n",
              "      <th>isPositive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PURCHASED FOR YOUNGSTER WHO\\nINHERITED MY \"TOO...</td>\n",
              "      <td>IDEAL FOR BEGINNER!</td>\n",
              "      <td>True</td>\n",
              "      <td>1361836800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unable to open or use</td>\n",
              "      <td>Two Stars</td>\n",
              "      <td>True</td>\n",
              "      <td>1452643200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Waste of money!!! It wouldn't load to my system.</td>\n",
              "      <td>Dont buy it!</td>\n",
              "      <td>True</td>\n",
              "      <td>1433289600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I attempted to install this OS on two differen...</td>\n",
              "      <td>I attempted to install this OS on two differen...</td>\n",
              "      <td>True</td>\n",
              "      <td>1518912000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I've spent 14 fruitless hours over the past tw...</td>\n",
              "      <td>Do NOT Download.</td>\n",
              "      <td>True</td>\n",
              "      <td>1441929600</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd620bfc-fff1-4298-a78a-67f12c83e393')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd620bfc-fff1-4298-a78a-67f12c83e393 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd620bfc-fff1-4298-a78a-67f12c83e393');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1beaa144-ac02-4ead-ac40-e41958e2e0af\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1beaa144-ac02-4ead-ac40-e41958e2e0af')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1beaa144-ac02-4ead-ac40-e41958e2e0af button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 70000,\n  \"fields\": [\n    {\n      \"column\": \"reviewText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66771,\n        \"samples\": [\n          \"It was defective and Amazon refused to replace it, even after admitting fault.\",\n          \"This is the best program to purchase mp3 music and play on your computer at home, I love\\nit!!! Awesome selection of songs..\",\n          \"\\\"Support\\\" just says, \\\"we know it doesn't work, we are trying to fix it.\\\"  That does not help. Windows seven has been out for months now, and was out in Beta many months before that. FIX IT, or give us back our money!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49276,\n        \"samples\": [\n          \"Where's the Help?\",\n          \"Skip the basic and GoPro\",\n          \"Great option when the portable devices aren't available.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"verified\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 114998579,\n        \"min\": 942192000,\n        \"max\": 1538438400,\n        \"num_unique_values\": 6256,\n        \"samples\": [\n          1021075200,\n          1033948800\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_votes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9626766304813036,\n        \"min\": 0.0,\n        \"max\": 7.110696122978827,\n        \"num_unique_values\": 226,\n        \"samples\": [\n          4.61512051684126,\n          6.084499413075172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isPositive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48433955809748475,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data analysis"
      ],
      "metadata": {
        "id": "OpEjoj-nxhyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display some examples from the dataset"
      ],
      "metadata": {
        "id": "zOPSpw37xfSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0]['reviewText']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nBp0JOjFxgyQ",
        "outputId": "d4ddaf73-da28-44d5-acb5-170d8a04a690"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PURCHASED FOR YOUNGSTER WHO\\nINHERITED MY \"TOO sMALL FOR ME\"\\nLAPTOP.  IDEAL FOR LEARNING A\\nFUTURE GOOD SKILL.  HER CHOICE\\nOF BOOKS IS A PLUS AS WAS THIS BOOK!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the number of samples"
      ],
      "metadata": {
        "id": "iO3Di4FRySnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCTymcB3yT7x",
        "outputId": "c839ee9f-61d3-4591-cc0d-8c1a2d44d2ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the label proportion (number of positive labels / negative labels)"
      ],
      "metadata": {
        "id": "blYxtd19xhLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"isPositive\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYdIvCWKxoay",
        "outputId": "6f9b4095-c1a7-4311-fca2-01b97b46ecf0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "isPositive\n",
              "1.0    43692\n",
              "0.0    26308\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the value count for verified"
      ],
      "metadata": {
        "id": "gVv7aT-RyD8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"verified\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jnq9TfiyGMk",
        "outputId": "11c5a4f7-a64c-4734-c1d1-91578cfa2907"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "verified\n",
              "True     47208\n",
              "False    22792\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove NaN values"
      ],
      "metadata": {
        "id": "K62ef7qhxtSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['reviewText'])\n",
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRJq3zM8xu0n",
        "outputId": "97905663-0f58-4d9b-fa17-4a4b485cda56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69988"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the dataset into training and validation"
      ],
      "metadata": {
        "id": "occ4XfPUyY_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, val_text, train_label, val_label = \\\n",
        "    train_test_split(df[\"reviewText\"].tolist(),\n",
        "                     df[\"isPositive\"].tolist(),\n",
        "                     test_size=0.10,\n",
        "                     shuffle=True,\n",
        "                     random_state=324)"
      ],
      "metadata": {
        "id": "JW8CXe06xvLL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text processing and Transformation"
      ],
      "metadata": {
        "id": "e-Plaf8dygiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the get tokenizer function from torchtext to download `basic_english` tokenizer"
      ],
      "metadata": {
        "id": "JDBXd5Rfy5HK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")"
      ],
      "metadata": {
        "id": "A3EjrvUsy_ZP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Counter() from collection, that we will use to compute the histogram of our tokens"
      ],
      "metadata": {
        "id": "YxeBrZ3CzEGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter()"
      ],
      "metadata": {
        "id": "2mEaQBfszAh6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the counter for each samples of your dataset\n",
        "\n",
        "`counter.update(tokenizer(\"...\"))`"
      ],
      "metadata": {
        "id": "D9wvSgRqzLEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for line in train_text:\n",
        "    counter.update(tokenizer(line))"
      ],
      "metadata": {
        "id": "b2kXFPrzzKk3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's display the counter. You can see that we have the count for each token"
      ],
      "metadata": {
        "id": "xhg4o6-lzVgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter"
      ],
      "metadata": {
        "id": "5-b9A9pJzRtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a vocabulary with words seen at least 5 (min_freq) times\n",
        "\n",
        "use torchtext vocab to create your vocabulary"
      ],
      "metadata": {
        "id": "yPeCzBkCza9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vocabulary with words seen at least 5 (min_freq) times\n",
        "vocab = torchtext.vocab.vocab(counter, min_freq=5)"
      ],
      "metadata": {
        "id": "EA1rQ0dOydBz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the unknow token and the pad token, using `insert_token` function"
      ],
      "metadata": {
        "id": "fvLnU-xFoNMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the unknown token\n",
        "# and use it by default for unknown words\n",
        "unk_token = '<unk>'\n",
        "vocab.insert_token(unk_token, 0)\n",
        "vocab.set_default_index(0)\n",
        "\n",
        "# Add the pad token\n",
        "pad_token = '<pad>'\n",
        "vocab.insert_token(pad_token, 1)"
      ],
      "metadata": {
        "id": "7a8j-oxm0L7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you have some examples"
      ],
      "metadata": {
        "id": "zKEkG3looXz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"'home' -> {vocab['home']}\")\n",
        "print(f\"'wash' -> {vocab['wash']}\")\n",
        "# unknown word (assume from test set)\n",
        "print(f\"'fhshbasdhb' -> {vocab['fhshbasdhb']}\")"
      ],
      "metadata": {
        "id": "P6EWdzgIoVNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can use the following mapper to tokenize the data\n",
        "text_transform_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]"
      ],
      "metadata": {
        "id": "aqC9s3A_oVXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before transform:\\t{train_text[37]}\")\n",
        "print(f\"After transform:\\t{text_transform_pipeline(train_text[37])}\")"
      ],
      "metadata": {
        "id": "N7tr7cYAEe2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write a function that modifies and pads our text data as needed. In this function, we'll truncate the text sequence when it exceeds a specified length (in this case, max_len=50). If the text is shorter than max_len, we'll append 1s to the end of the sequence, representing the padding token."
      ],
      "metadata": {
        "id": "e375wYg6EroP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformText(text_list, max_len):\n",
        "    # Transform the text\n",
        "    transformed_data = [text_transform_pipeline(text)[:max_len] for text in text_list]\n",
        "\n",
        "    # Pad zeros if the text is shoter than max_len\n",
        "    for data in transformed_data:\n",
        "        data[len(data) : max_len] = np.ones(max_len - len(data))\n",
        "\n",
        "    return torch.tensor(transformed_data, dtype=torch.int64)"
      ],
      "metadata": {
        "id": "zWtGIIKXEsTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text[300]"
      ],
      "metadata": {
        "id": "cw8gJ7j6cekz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = train_text[7:9]\n",
        "print(f\"Text: {text}\\n\")\n",
        "print(f\"Num sentences: {len(text)}\\n\")\n",
        "tt = transformText(text, max_len=50)\n",
        "print(f\"Transformed text: \\n{tt}\\n\")\n",
        "print(f\"Shape of transformed text: {tt.shape}\")"
      ],
      "metadata": {
        "id": "E6amnvBJchOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the transformText() function and create the data loaders. Here, we use max_len=100 to consider the first 100 words in the text.\n",
        "\n",
        "Use TensorDataset to build the dataset from you tokens and labels."
      ],
      "metadata": {
        "id": "anZmiuiMcxwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 100\n",
        "batch_size = 32\n",
        "\n",
        "# Pass transformed and padded data to dataset\n",
        "# Create data loaders\n",
        "train_dataset = TensorDataset(\n",
        "    transformText(train_text, max_len), torch.tensor(train_label)\n",
        ")\n",
        "val_dataset = TensorDataset(transformText(val_text, max_len), torch.tensor(val_label))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "nbPzTjMlcmZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the model"
      ],
      "metadata": {
        "id": "zXGF7fRMduP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this illustration, we'll leverage GloVe word vectors, specifically those from the '6B' dataset with dimensions of 300. This dataset encompasses 6 billion words and phrases, each represented by a vector containing 300 numerical values. The code below demonstrates how to access these word vectors and construct an embedding matrix. We'll establish a linkage between our vocabulary indices and the GloVe embeddings utilizing the get_vecs_by_tokens() function"
      ],
      "metadata": {
        "id": "eiYwDPX-c_V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove = GloVe(name=\"6B\", dim=300)\n",
        "embedding_matrix = glove.get_vecs_by_tokens(vocab.get_itos())"
      ],
      "metadata": {
        "id": "Ofx9VR68c_nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper parameters of the model that you can tune"
      ],
      "metadata": {
        "id": "wJA7VyqNdFh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of the state vectors\n",
        "hidden_size = 8\n",
        "\n",
        "# General NN training parameters\n",
        "learning_rate = 0.001\n",
        "epochs = 25\n",
        "\n",
        "# Embedding vector and vocabulary sizes\n",
        "embed_size = 300  # glove.6B.300d.txt\n",
        "vocab_size = len(vocab.get_itos())"
      ],
      "metadata": {
        "id": "rG7gNQ7EdBg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before proceeding, it's essential to ensure our data is properly formatted for the subsequent stages. Our model comprises the following layers:\n",
        "\n",
        "- Embedding Layer: Responsible for mapping words/tokens to word vectors.\n",
        "- RNN Layer: In this instance, we employ a simple RNN model, consisting of two stacked RNN layers. Further insights into the RNN architecture can be found here.\n",
        "- Linear Layer: Utilized for the final prediction of 'isPositive', this layer consists of a single neuron."
      ],
      "metadata": {
        "id": "yzHO1xpNdRPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding documentation: https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"
      ],
      "metadata": {
        "id": "6b9U-xlvdNgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.RNN(\n",
        "            embed_size, hidden_size, num_layers=num_layers\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Linear(hidden_size*max_len, 1)\n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeddings = self.embedding(inputs)\n",
        "        # Call RNN layer\n",
        "        outputs, _ = self.rnn(embeddings)\n",
        "        # Use the output of each time step\n",
        "        # Send it all together to the linear layer\n",
        "        outs = self.linear(outputs.reshape(outputs.shape[0], -1))\n",
        "        return self.act(outs)\n",
        "\n",
        "model = Net(vocab_size, embed_size, hidden_size, num_layers=2)\n",
        "\n",
        "# Initialize the weights\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "    if type(m) == nn.RNN:\n",
        "        for param in m._flat_weights_names:\n",
        "            if \"weight\" in param:\n",
        "                nn.init.xavier_uniform_(m._parameters[param])\n"
      ],
      "metadata": {
        "id": "JqZgUeqkdO0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's initialize this network. Then, we will need to make the embedding layer use our GloVe word vectors."
      ],
      "metadata": {
        "id": "4G5h6IqjdZNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `model.embedding.weight.data.copy_` to set the pretrained embedding parameters and freeze the weight"
      ],
      "metadata": {
        "id": "g4P-YG9OdffV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We set the embedding layer's parameters from GloVe\n",
        "model.embedding.weight.data.copy_(embedding_matrix)\n",
        "\n",
        "# We won't change/train the embedding layer\n",
        "model.embedding.weight.requires_grad = False"
      ],
      "metadata": {
        "id": "qGGI1PGsdZm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build loss and optimizer"
      ],
      "metadata": {
        "id": "umK2FIEWdoVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting our trainer\n",
        "trainer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# We will use Binary Cross-entropy loss\n",
        "# reduction=\"sum\" sums the losses for given output and target\n",
        "cross_ent_loss = nn.BCELoss(reduction=\"sum\")"
      ],
      "metadata": {
        "id": "CW1UeSQKdpRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now build the train / validation loop"
      ],
      "metadata": {
        "id": "5EEzApEafbL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the compute device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.apply(init_weights)\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    training_loss = 0\n",
        "    val_loss = 0\n",
        "    # Training loop, train the network\n",
        "    for data, target in train_loader:\n",
        "        trainer.zero_grad()\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        L = cross_ent_loss(output.squeeze(1), target)\n",
        "        training_loss += L.item()\n",
        "        L.backward()\n",
        "        trainer.step()\n",
        "\n",
        "    # Validate the network, no training (no weight update)\n",
        "    for data, target in val_loader:\n",
        "        val_predictions = model(data.to(device))\n",
        "        L = cross_ent_loss(val_predictions.squeeze(1), target.to(device))\n",
        "        val_loss += L.item()\n",
        "\n",
        "    # Let's take the average losses\n",
        "    training_loss = training_loss / len(train_label)\n",
        "    val_loss = val_loss / len(val_label)\n",
        "\n",
        "    end = time.time()\n",
        "    print(\n",
        "        f\"Epoch {epoch}. Train_loss {training_loss}. Val_loss {val_loss}. Seconds {end-start}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "Eejt8Ugrfce2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test our classifier"
      ],
      "metadata": {
        "id": "dh4diogNffIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display some prediction and display the confusion matrix / accuracy / precision / recall / f1score on the validation set"
      ],
      "metadata": {
        "id": "eLEy1RTNfjOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_predictions = []\n",
        "for data, target in val_loader:\n",
        "    val_preds = model(data.to(device))\n",
        "    val_predictions.extend(\n",
        "        [np.rint(val_pred)[0] for val_pred in val_preds.detach().cpu().numpy()]\n",
        "    )\n",
        "print(val_predictions[:10])"
      ],
      "metadata": {
        "id": "e6OgMfihfgu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improvement:\n",
        "\n",
        "- Change the batch size\n",
        "- Add more layers\n",
        "- Use GRU / LSTM layers"
      ],
      "metadata": {
        "id": "ZZz7kCYtgcra"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQk1aqLYgiSv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}